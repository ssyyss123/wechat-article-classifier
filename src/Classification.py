import pandas as pd
import requests
import time
import os
import re
import markdown
from bs4 import BeautifulSoup
import shutil
from datetime import datetime
import warnings
import json
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥appæ¨¡å—
sys.path.append(os.path.dirname(__file__))

# å¿½ç•¥ pandas çš„ SettingWithCopyWarning è­¦å‘Š
warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)

# --- 1. é…ç½®å‚æ•° ---

# å¯¼å…¥å…±äº«é…ç½®å‡½æ•°
try:
    from app import get_default_ollama_config
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œå®šä¹‰æœ¬åœ°é»˜è®¤é…ç½®ä½œä¸ºå¤‡ç”¨
    def get_default_ollama_config():
        return {
            'ollama_url': 'http://localhost:11434',
            'model_id': 'qwen3:8b',
            'temperature': 0.3,
            'timeout': 80,
            'max_retries': 3,
            'max_summary_length': 600,
            'num_ctx': 5120,
            'min_text_length': 150,
        }

def load_ollama_config():
    """åŠ è½½Ollamaé…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), 'config', 'ollama_config.json')
    default_config = get_default_ollama_config()
    
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            # åˆå¹¶é»˜è®¤é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨
            for key, value in default_config.items():
                if key not in config:
                    config[key] = value
            return config
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return default_config.copy()
    else:
        print("é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return default_config.copy()

def load_prompt_config():
    """åŠ è½½ç³»ç»Ÿæç¤ºè¯é…ç½®"""
    config_path = os.path.join(os.path.dirname(__file__), 'config', 'prompt_config.json')
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
                return config
        except Exception as e:
            print(f"åŠ è½½æç¤ºè¯é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    return None

def generate_system_prompt_from_config(config):
    """æ ¹æ®é…ç½®ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
    if not config:
        return DEFAULT_SYSTEM_PROMPT
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    prompt_parts = []
    
    # è§’è‰²å®šä¹‰
    if config.get('role_definition'):
        prompt_parts.append(config['role_definition'])
    
    # æ— å…³åˆ¤å®šè§„åˆ™
    if config.get('irrelevant_rules'):
        prompt_parts.append("ã€æ— å…³åˆ¤å®šè§„åˆ™ã€‘ï¼ˆä»å‰å¾€åä¾æ¬¡åˆ¤å®šï¼Œæ»¡è¶³ä»»ä¸€æ¡å³è¾“å‡º\"æ— å…³\"ï¼‰ï¼š")
        for i, rule in enumerate(config['irrelevant_rules'], 1):
            prompt_parts.append(f"{i}.{rule} â†’ æ— å…³")
    
    # åˆ†ç±»æ ‡å‡†
    if config.get('categories'):
        prompt_parts.append("ã€åˆ†ç±»æ ‡å‡†ã€‘ï¼ˆä»…å½“é€šè¿‡æ— å…³æ£€æµ‹å…¨éƒ¨é€šè¿‡åæ‰§è¡Œï¼Œå¦åˆ™ä¸å…è®¸æ‰§è¡Œåˆ†ç±»ï¼‰ï¼š")
        for category in config['categories']:
            name = category.get('name', '')
            description = category.get('description', '')
            if name and description:
                prompt_parts.append(f"{name}ï¼š{description}")
    
    # è¾“å‡ºè¦æ±‚
    category_names = [cat.get('name', '') for cat in config.get('categories', []) if cat.get('name')]
    if category_names:
        prompt_parts.append("ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š")
        prompt_parts.append("-å¿…é¡»ä¸¥æ ¼æŒ‰ä¼˜å…ˆçº§åˆ¤å®š\"æ— å…³\"ï¼Œä½ éœ€è¦ä»”ç»†é˜…è¯»å…¨æ–‡ï¼Œç†è§£æ–‡å­—è¡¨è¾¾çš„ä¸»æ—¨ï¼Œè€Œä¸æ˜¯ä»…ä¾é ç‰‡é¢å­—çœ¼è¿›è¡Œåˆ¤æ–­")
        categories_str = '/'.join(category_names + ['æ— å…³'])
        prompt_parts.append(f"-ä»…è¾“å‡ºä»¥ä¸‹{len(category_names)+1}ç§ä¹‹ä¸€ï¼ˆä¸åŠ ä»»ä½•è§£é‡Šï¼‰ï¼š {categories_str}")
    
    # å‚è€ƒä¾‹å­
    if config.get('examples'):
        prompt_parts.append("ã€å‚è€ƒä¾‹å­ã€‘")
        for example in config['examples']:
            category = example.get('category', '')
            content = example.get('content', '')
            if category and content:
                prompt_parts.append(f"{category}ï¼š{content}")
    
    prompt_parts.append("/no_think")
    
    return '\n'.join(prompt_parts)

def update_categories_from_config(config):
    """æ ¹æ®é…ç½®æ›´æ–°åˆ†ç±»æ˜ å°„"""
    global VALID_CATEGORIES, FOLDER_CATEGORIES
    
    if not config or not config.get('categories'):
        return
    
    # ä»é…ç½®ä¸­æå–åˆ†ç±»åç§°
    category_names = [cat.get('name', '') for cat in config['categories'] if cat.get('name')]
    
    if category_names:
        # æ›´æ–°æœ‰æ•ˆåˆ†ç±»ï¼ˆåŒ…æ‹¬"æ— å…³"ï¼‰
        VALID_CATEGORIES = category_names + ["æ— å…³"]
        # æ›´æ–°æ–‡ä»¶å¤¹åˆ†ç±»ï¼ˆä¸åŒ…æ‹¬"æ— å…³"ï¼‰
        FOLDER_CATEGORIES = category_names
        print(f"åˆ†ç±»æ˜ å°„å·²æ›´æ–°: {VALID_CATEGORIES}")

def reload_config():
    """é‡æ–°åŠ è½½é…ç½®å¹¶æ›´æ–°å…¨å±€å˜é‡"""
    global OLLAMA_URL, MODEL_ID, TEMPERATURE, TIMEOUT, MAX_RETRIES, MAX_SUMMARY_LENGTH, NUM_CTX, MIN_TEXT_LENGTH, SYSTEM_PROMPT
    
    # åŠ è½½Ollamaé…ç½®
    ollama_config = load_ollama_config()
    OLLAMA_URL = ollama_config['ollama_url'] + '/api/chat'
    MODEL_ID = ollama_config['model_id']
    TEMPERATURE = ollama_config['temperature']
    TIMEOUT = ollama_config['timeout']
    MAX_RETRIES = ollama_config['max_retries']
    MAX_SUMMARY_LENGTH = ollama_config['max_summary_length']
    NUM_CTX = ollama_config['num_ctx']
    MIN_TEXT_LENGTH = ollama_config['min_text_length']
    
    # åŠ è½½ç³»ç»Ÿæç¤ºè¯é…ç½®
    prompt_config = load_prompt_config()
    if prompt_config:
        # æ ¹æ®é…ç½®ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
        SYSTEM_PROMPT = generate_system_prompt_from_config(prompt_config)
        # æ›´æ–°åˆ†ç±»æ˜ å°„
        update_categories_from_config(prompt_config)
        print(f"ç³»ç»Ÿæç¤ºè¯é…ç½®å·²åŠ è½½å¹¶åº”ç”¨")
    else:
        # ä½¿ç”¨Ollamaé…ç½®ä¸­çš„ç³»ç»Ÿæç¤ºè¯æˆ–é»˜è®¤å€¼
        SYSTEM_PROMPT = ollama_config.get('system_prompt', DEFAULT_SYSTEM_PROMPT)
        print(f"ä½¿ç”¨é»˜è®¤ç³»ç»Ÿæç¤ºè¯é…ç½®")
    
    print(f"Ollamaé…ç½®å·²é‡æ–°åŠ è½½: {ollama_config}")
    return ollama_config

# åŠ è½½é…ç½®
config = load_ollama_config()
OLLAMA_URL = config['ollama_url'] + '/api/chat'
MODEL_ID = config['model_id']
TEMPERATURE = config['temperature']
TIMEOUT = config['timeout']
MAX_RETRIES = config['max_retries']
MAX_SUMMARY_LENGTH = config['max_summary_length']
NUM_CTX = config['num_ctx']
MIN_TEXT_LENGTH = config['min_text_length']

# è·¯å¾„é…ç½® (!!! è¯·æ ¹æ®æ‚¨çš„å®é™…æƒ…å†µä¿®æ”¹è¿™é‡Œçš„è·¯å¾„ !!!)
OUTPUT_FOLDER = r"C:\Users\27549\OneDrive - whcqadc\æ¡Œé¢\test2"  # æ–°çš„åˆ†ç±»ç»“æœè¾“å‡ºæ–‡ä»¶å¤¹
CHANGES_CSV_PATH = os.path.join(OUTPUT_FOLDER, "èµ„æ–™æ±‡æ€».csv")  # è®°å½•åˆ†ç±»ç»“æœçš„CSV

# åˆ†ç±»ç›®å½•æ˜ å°„ (ç”¨äºåˆ›å»ºæ–‡ä»¶å¤¹)
# æ³¨æ„: è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨æ¨¡å‹çš„è¾“å‡ºä¸­æ–‡åä½œä¸ºæ–‡ä»¶å¤¹å
VALID_CATEGORIES = ["åˆè§„é£æ§ç±»", "ç»è¥å†³ç­–ç±»", "è¿è¥æ“ä½œç±»", "åˆ›æ–°å®è·µç±»", "æ— å…³"]
# ç”¨äºåˆ›å»ºæ–‡ä»¶å¤¹çš„åˆ†ç±»ï¼ˆä¸åŒ…æ‹¬"æ— å…³"ï¼‰
FOLDER_CATEGORIES = ["åˆè§„é£æ§ç±»", "ç»è¥å†³ç­–ç±»", "è¿è¥æ“ä½œç±»", "åˆ›æ–°å®è·µç±»"]

# ç³»ç»Ÿæç¤ºè¯ (ä¸åŸè„šæœ¬ä¿æŒä¸€è‡´)
# é»˜è®¤ç³»ç»Ÿæç¤ºè¯
DEFAULT_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€åä¸“æ³¨äºçº¿ä¸‹å¿«æ¶ˆå“é›¶å”®è¡Œä¸šæ–‡ç« åˆ†ç±»çš„ä¸“å®¶ï¼Œè´Ÿè´£ä¸ºå¤§å–åœº/è¶…å¸‚/ä¾¿åˆ©åº—ä¼ä¸šç­›é€‰å’Œå½’ç±»å…·æœ‰å®æ“ä»·å€¼çš„æ¡ˆä¾‹æˆ–ç»è¥è§„èŒƒç±»å†…å®¹ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è§„åˆ™æ‰§è¡Œï¼š
ã€æ— å…³åˆ¤å®šè§„åˆ™ã€‘ï¼ˆä»å‰å¾€åä¾æ¬¡åˆ¤å®šï¼Œæ»¡è¶³ä»»ä¸€æ¡å³è¾“å‡º"æ— å…³"ï¼‰ï¼š
1.æ–‡å­—ä¸»æ—¨éçº¿ä¸‹å¿«æ¶ˆå“é›¶å”®ä¸šå¼ºç›¸å…³ â†’ æ— å…³
2.æœªåŒ…å«å…·ä½“ä¼ä¸šå®æ“æ¡ˆä¾‹/è§„èŒƒ â†’ æ— å…³
3.ä¸å±äºå¤§å–åœº/è¶…å¸‚/ä¾¿åˆ©åº—ä¹‹ä¸€çš„é›¶å”®ä¼ä¸š â†’ æ— å…³
4.å­˜åœ¨ï¼šåŸ¹è®­ç­/å…¬ç¤º/å¹¿å‘Š/è¯¾ç¨‹/ä¼šè®®/é‚€çº¦/è¯„å¥–/æ‹›è˜/æ‹›å‹Ÿ/æ¨å¹¿/è®ºå›/å¹´ä¼šä»»ä¸€æ€§è´¨çš„å†…å®¹â†’ æ— å…³
5.æ¶‰åŠç”µå•†/ç›´æ’­ç­‰çº¿ä¸Šæ¸ é“ â†’ æ— å…³
6.æ‰€è¿°æ˜¯ä¾›åº”å•†/å“ç‰Œæ–¹/é¤é¥®ä¸š â†’ æ— å…³
7.çº¯æ–°é—»/æŠ¥é“/æ•°æ®/ä¸»è§‚å†…å®¹/æ—¶æ•ˆä¿¡æ¯ â†’ æ— å…³
8.å«å¤§é‡å›¾ç‰‡urlé“¾æ¥ â†’ æ— å…³
ã€åˆ†ç±»æ ‡å‡†ã€‘ï¼ˆä»…å½“é€šè¿‡æ— å…³æ£€æµ‹å…¨éƒ¨é€šè¿‡åæ‰§è¡Œï¼Œå¦åˆ™ä¸å…è®¸æ‰§è¡Œåˆ†ç±»ï¼‰ï¼š
åˆè§„é£æ§ç±»ï¼šé£é™©äº‹ä»¶å¤„ç†/ç›‘ç®¡åˆè§„æ¡ˆä¾‹
ç»è¥å†³ç­–ç±»ï¼šæˆ˜ç•¥è°ƒæ•´/å‘å±•ç»è¥å†³ç­–æ¡ˆä¾‹
è¿è¥æ“ä½œç±»ï¼šæ ‡å‡†åŒ–æµç¨‹/æ‰§è¡Œç»†åˆ™
åˆ›æ–°å®è·µç±»ï¼šæ–°æŠ€æœ¯åº”ç”¨/å•†ä¸šæ¨¡å¼åˆ›æ–°æ¡ˆä¾‹
ã€è¾“å‡ºè¦æ±‚ã€‘ï¼š
-å¿…é¡»ä¸¥æ ¼æŒ‰ä¼˜å…ˆçº§åˆ¤å®š"æ— å…³"ï¼Œä½ éœ€è¦ä»”ç»†é˜…è¯»å…¨æ–‡ï¼Œç†è§£æ–‡å­—è¡¨è¾¾çš„ä¸»æ—¨ï¼Œè€Œä¸æ˜¯ä»…ä¾é ç‰‡é¢å­—çœ¼è¿›è¡Œåˆ¤æ–­
-ä»…è¾“å‡ºä»¥ä¸‹5ç§ä¹‹ä¸€ï¼ˆä¸åŠ ä»»ä½•è§£é‡Šï¼‰ï¼š åˆè§„é£æ§ç±»/ç»è¥å†³ç­–ç±»/è¿è¥æ“ä½œç±»/åˆ›æ–°å®è·µç±»/æ— å…³
ã€å‚è€ƒä¾‹å­ã€‘
åˆ›æ–°å®è·µç±»ï¼šä¸Šå“å•†è¶…æ™ºæ…§é›¶å”®é©±åŠ¨æ–°å¢é•¿ï¼Œç„•å‘è¡Œä¸šæ–°æ´»åŠ›
ç»è¥å†³ç­–ç±»ï¼šä»åš2Bèµ·å®¶åˆ°é 2Cé€†è¢­ï¼Œå±±å§†åœ¨ä¸­å›½çš„ç”Ÿæ„ç»
è¿è¥æ“ä½œç±»ï¼šèƒ–ä¸œæ¥è¿è¥è€ƒæ ¸æ ‡å‡†
åˆè§„é£æ§ç±»ï¼šèƒ–ä¸œæ¥"çº¢å†…è£¤äº‹ä»¶"ï¼Œä¸€åœºä¿¡ä»»å±æœºä¸‹çš„ä¼ä¸šåˆè§„è­¦ç¤ºå½•
/no_think
"""

# åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯
prompt_config = load_prompt_config()
if prompt_config:
    # æ ¹æ®é…ç½®ç”Ÿæˆç³»ç»Ÿæç¤ºè¯
    SYSTEM_PROMPT = generate_system_prompt_from_config(prompt_config)
    # æ›´æ–°åˆ†ç±»æ˜ å°„
    update_categories_from_config(prompt_config)
else:
    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ç³»ç»Ÿæç¤ºè¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    SYSTEM_PROMPT = config.get('system_prompt', DEFAULT_SYSTEM_PROMPT)

# --- 2. è¾…åŠ©å‡½æ•° (éƒ¨åˆ†å¤ç”¨åŸè„šæœ¬) ---

def extract_title_from_filename(filename):
    """ä»æ–‡ä»¶åä¸­æå–æ ‡é¢˜ï¼Œç”¨äºå’ŒExcelè¿›è¡ŒåŒ¹é…"""
    # ç§»é™¤.mdåç¼€
    base_name = os.path.splitext(filename)[0]
    # å°è¯•åŒ¹é… [YYYY-MM-DD]æ ‡é¢˜ æ ¼å¼
    pattern = r'\[\d{4}-\d{2}-\d{2}\](.*)'
    match = re.match(pattern, base_name)
    if match:
        return match.group(1).strip()
    # å¦‚æœä¸åŒ¹é…ï¼Œåˆ™è¿”å›æ•´ä¸ªæ–‡ä»¶åï¼ˆæ— åç¼€ï¼‰
    return base_name.strip()

def normalize_string_for_matching(text):
    """æ¸…ç†å­—ç¬¦ä¸²ï¼Œç§»é™¤æ‰€æœ‰éå­—æ¯å’Œæ•°å­—çš„å­—ç¬¦ï¼Œå¹¶è½¬ä¸ºå°å†™ï¼Œç”¨äºæ¨¡ç³ŠåŒ¹é…"""
    if not isinstance(text, str):
        return ""
    # ç§»é™¤éå­—æ¯ã€éæ•°å­—ã€éä¸­æ–‡å­—ç¬¦
    return re.sub(r'[^\w\u4e00-\u9fa5]', '', text).lower()

def extract_text_from_markdown(md_file):
    """ä»markdownæ–‡ä»¶ä¸­æå–çº¯æ–‡æœ¬"""
    with open(md_file, 'r', encoding='utf-8') as f:
        md_content = f.read()
    html = markdown.markdown(md_content)
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text(separator=' ', strip=True)

def create_summary(text, max_length=MAX_SUMMARY_LENGTH):
    """åˆ›å»ºæ–‡ç« æ‘˜è¦"""
    return text[:max_length]

def clean_response(content):
    """æ¸…æ´—å“åº”å†…å®¹"""
    cleaned = re.sub(r'<think>.*?</think>', '', content, flags=re.DOTALL).strip()
    # ç¡®ä¿å“åº”æ˜¯æœ‰æ•ˆçš„åˆ†ç±»
    if cleaned not in VALID_CATEGORIES:
        return "æ— å…³"  # å¦‚æœæ¨¡å‹è¾“å‡ºæ„å¤–å†…å®¹ï¼Œé»˜è®¤ä¸º"æ— å…³"
    return cleaned

def query_ollama_with_retry(prompt):
    """å¸¦é‡è¯•æœºåˆ¶çš„OllamaæŸ¥è¯¢"""
    user_prompt = f"{prompt} /no think"
    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {"role": "user", "content": user_prompt}
    ]
    payload = {
        "model": MODEL_ID, "messages": messages, "stream": False,
        "options": {"temperature": TEMPERATURE, "num_ctx": NUM_CTX}
    }

    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(OLLAMA_URL, json=payload, timeout=TIMEOUT)
            response.raise_for_status()
            content = response.json()["message"]["content"]
            return clean_response(content)
        except requests.exceptions.RequestException as e:
            if attempt == MAX_RETRIES - 1:
                return f"[é”™è¯¯] è¯·æ±‚å¤±è´¥: {str(e)}"
            time.sleep(2)
    return "[é”™è¯¯] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°"


def initialize_classification(classification_folder=None, category_name=None):
    """
    åˆå§‹åŒ–åˆ†ç±»ç¯å¢ƒï¼Œåˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆä¸åŒ…æ‹¬"æ— å…³"æ–‡ä»¶å¤¹ï¼‰
    """
    # ä½¿ç”¨ä¼ å…¥çš„åˆ†ç±»æ–‡ä»¶å¤¹æˆ–é»˜è®¤æ–‡ä»¶å¤¹
    current_output_folder = classification_folder if classification_folder else OUTPUT_FOLDER
    
    # å¦‚æœæŒ‡å®šäº†å¤§ç±»åç§°ï¼Œåœ¨åˆ†ç±»æ–‡ä»¶å¤¹ä¸‹åˆ›å»ºå¤§ç±»æ–‡ä»¶å¤¹
    if category_name:
        current_output_folder = os.path.join(current_output_folder, category_name)
    
    os.makedirs(current_output_folder, exist_ok=True)
    for category in FOLDER_CATEGORIES:
        category_folder = os.path.join(current_output_folder, category)
        os.makedirs(category_folder, exist_ok=True)
    print(f"åˆ†ç±»è¾“å‡ºæ–‡ä»¶å¤¹å·²åˆå§‹åŒ–: {current_output_folder}")
    
    return current_output_folder

def classify_single_article(file_path, sequence_number, article_info=None, classification_folder=None, category_name=None):
    """
    å¯¹å•ç¯‡æ–‡ç« è¿›è¡Œåˆ†ç±»
    è¿”å›åˆ†ç±»è®°å½•å­—å…¸ï¼Œå¦‚æœåˆ†ç±»ä¸ºæ— å…³åˆ™è¿”å›None
    """
    filename = os.path.basename(file_path)
    
    try:
        # æå–æ–‡æœ¬å†…å®¹
        text_content = extract_text_from_markdown(file_path)
        if not text_content.strip():
            print(f"è·³è¿‡ç©ºæ–‡ä»¶: {filename}")
            return None
        
        # å¦‚æœå†…å®¹è¿‡çŸ­ï¼Œç›´æ¥å½’ä¸º"æ— å…³"
        if len(text_content) < MIN_TEXT_LENGTH:
            classification_result = "æ— å…³"
            print(f"â© æ–‡ä»¶ '{filename}' å†…å®¹è¿‡çŸ­ï¼ˆ{len(text_content)}å­— < {MIN_TEXT_LENGTH}å­—ï¼‰ï¼Œè‡ªåŠ¨å½’ä¸º'æ— å…³'ã€‚")
        else:
            # åˆ›å»ºæ‘˜è¦
            summary = create_summary(text_content)
            # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†ç±»
            classification_result = query_ollama_with_retry(summary)
        
        if classification_result.startswith("[é”™è¯¯]"):
            print(f"âŒ æ–‡ä»¶ '{filename}' å¤„ç†å¤±è´¥: {classification_result}")
            return None
        
        # å¦‚æœåˆ†ç±»ä¸ºæ— å…³ï¼Œè¿”å›Noneï¼ˆä¸ä¿å­˜æ–‡ä»¶å’Œè®°å½•ï¼‰
        if classification_result == "æ— å…³":
            print(f"âœ… æ–‡ä»¶ '{filename}' -> åˆ†ç±»ä¸º: '{classification_result}'ï¼ˆå°†è¢«åˆ é™¤ï¼‰")
            return None
        
        # æ£€æŸ¥ç›®æ ‡åˆ†ç±»ç›®å½•æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶
        # ä½¿ç”¨ä¼ å…¥çš„åˆ†ç±»æ–‡ä»¶å¤¹æˆ–é»˜è®¤æ–‡ä»¶å¤¹
        current_output_folder = classification_folder if classification_folder else OUTPUT_FOLDER
        
        # å¦‚æœæŒ‡å®šäº†å¤§ç±»åç§°ï¼Œåœ¨åˆ†ç±»æ–‡ä»¶å¤¹ä¸‹åˆ›å»ºå¤§ç±»æ–‡ä»¶å¤¹
        if category_name:
            current_output_folder = os.path.join(current_output_folder, category_name)
        
        target_folder = os.path.join(current_output_folder, classification_result)
        target_path = os.path.join(target_folder, filename)
        
        if os.path.exists(target_path):
            print(f"âš ï¸ æ–‡ä»¶ '{filename}' åœ¨åˆ†ç±»ç›®å½•ä¸­å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜å’Œè®°å½•")
            return None
        
        # å¤åˆ¶æ–‡ä»¶åˆ°æ–°çš„åˆ†ç±»ç›®å½•
        shutil.copy2(file_path, target_path)
        
        # åˆ›å»ºåˆ†ç±»è®°å½•
        file_title = extract_title_from_filename(filename)
        record = {
            "åºå·": sequence_number,
            "å¤§ç±»": category_name if category_name else "æ ¸å¿ƒæ¡ˆä¾‹åº“",
            "å°ç±»": classification_result,
            "æ–‡æ¡£åç§°": file_title,
            "å…¥åº“æ—¥æœŸ": datetime.now().strftime("%Y-%m-%d"),
            "æ¥æº": article_info.get("link", "") if article_info else "",
            "å‘å¸ƒæ—¥æœŸ": ""
        }
        
        # å¤„ç†å‘å¸ƒæ—¥æœŸ
        if article_info and article_info.get("create_time"):
            try:
                # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ—¥æœŸ
                publish_date = datetime.fromtimestamp(article_info["create_time"]).strftime("%Y-%m-%d")
                record["å‘å¸ƒæ—¥æœŸ"] = publish_date
            except:
                record["å‘å¸ƒæ—¥æœŸ"] = ""
        
        print(f"âœ… æ–‡ä»¶ '{filename}' -> åˆ†ç±»ä¸º: '{classification_result}'")
        return record
        
    except Exception as e:
        print(f"ğŸ”¥ å¤„ç†æ–‡ä»¶ '{filename}' æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}")
        return None

def save_classification_results(classification_records, output_folder=None, category_name=None):
    """
    ä¿å­˜åˆ†ç±»ç»“æœåˆ°CSVæ–‡ä»¶
    """
    if classification_records:
        df_results = pd.DataFrame(classification_records)
        
        # ä½¿ç”¨ä¼ å…¥çš„è¾“å‡ºæ–‡ä»¶å¤¹æˆ–é»˜è®¤æ–‡ä»¶å¤¹
        current_output_folder = output_folder if output_folder else OUTPUT_FOLDER
        
        # å¦‚æœæŒ‡å®šäº†å¤§ç±»åç§°ï¼Œåœ¨åˆ†ç±»æ–‡ä»¶å¤¹ä¸‹åˆ›å»ºå¤§ç±»æ–‡ä»¶å¤¹
        if category_name:
            current_output_folder = os.path.join(current_output_folder, category_name)
        
        csv_path = os.path.join(current_output_folder, "èµ„æ–™æ±‡æ€».csv")
        
        # ç¡®ä¿è¾“å‡ºæ–‡ä»¶å¤¹å­˜åœ¨
        if not os.path.exists(current_output_folder):
            os.makedirs(current_output_folder)
        
        # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿½åŠ ï¼Œå¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
        if os.path.exists(csv_path):
            # è¯»å–ç°æœ‰æ•°æ®
            existing_df = pd.read_csv(csv_path, encoding='utf-8-sig')
            # åˆå¹¶æ•°æ®
            combined_df = pd.concat([existing_df, df_results], ignore_index=True)
            # é‡æ–°ç¼–å·åºå·åˆ—
            combined_df['åºå·'] = range(1, len(combined_df) + 1)
            # ä¿å­˜åˆå¹¶åçš„æ•°æ®
            combined_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"æˆåŠŸï¼è¿½åŠ è®°å½• {len(classification_records)} æ¡æ–‡æ¡£åˆ†ç±»ç»“æœã€‚")
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥ä¿å­˜
            df_results.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"æˆåŠŸï¼æ–°å»ºè®°å½• {len(classification_records)} æ¡æ–‡æ¡£åˆ†ç±»ç»“æœã€‚")
        
        print(f"åˆ†ç±»ç»“æœå·²ä¿å­˜è‡³: {csv_path}")
        
        # æ˜¾ç¤ºåˆ†ç±»ç»Ÿè®¡
        print("\næœ¬æ‰¹æ¬¡åˆ†ç±»ç»Ÿè®¡:")
        for category in VALID_CATEGORIES:
            category_count = len([r for r in classification_records if r.get('å°ç±»') == category])
            if category_count > 0:
                print(f"   - {category}: {category_count} ä¸ªæ–‡ä»¶")
    else:
        print("æœ¬æ¬¡è¿è¡Œæ²¡æœ‰æ£€æµ‹åˆ°ä»»ä½•å¯å¤„ç†çš„æ–‡ä»¶ã€‚")

def classify_wechat_articles(articles, source_directory, account_nickname, classification_folder=None, category_name=None):
    """
    ä¸“é—¨ä¸ºå¾®ä¿¡æ–‡ç« åˆ†ç±»è®¾è®¡çš„å‡½æ•°ï¼ˆä¿ç•™åŸæœ‰åŠŸèƒ½ï¼‰
    """
    print("--- å¼€å§‹æ‰§è¡Œå¾®ä¿¡æ–‡ç« åˆ†ç±»ä»»åŠ¡ ---")

    # åˆå§‹åŒ–åˆ†ç±»ç¯å¢ƒ
    actual_output_folder = initialize_classification(classification_folder, category_name)

    classification_records = []
    total_files_processed = 0
    
    # è·å–æºç›®å½•ä¸­çš„æ‰€æœ‰markdownæ–‡ä»¶
    if not os.path.isdir(source_directory):
        print(f"é”™è¯¯ï¼šæºç›®å½• '{source_directory}' ä¸å­˜åœ¨ã€‚")
        return

    md_files = [f for f in os.listdir(source_directory) if f.endswith('.md')]
    if not md_files:
        print("æºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°Markdownæ–‡ä»¶ã€‚")
        return

    total_files = len(md_files)
    print(f"å¼€å§‹å¤„ç† {total_files} ä¸ªæ–‡ä»¶...")
    
    for index, filename in enumerate(md_files, 1):
        file_path = os.path.join(source_directory, filename)
        total_files_processed += 1
        
        progress_percent = (index / total_files) * 100
        print(f"[{index}/{total_files}] ({progress_percent:.1f}%) æ­£åœ¨å¤„ç†: {filename}")
        
        # æŸ¥æ‰¾å¯¹åº”çš„æ–‡ç« ä¿¡æ¯
        article_info = None
        file_title = extract_title_from_filename(filename)
        
        for article in articles:
            if article.get("title") and normalize_string_for_matching(article["title"]) == normalize_string_for_matching(file_title):
                article_info = article
                break
        
        # ä½¿ç”¨å•ç¯‡æ–‡ç« åˆ†ç±»å‡½æ•°
        record = classify_single_article(file_path, index, article_info, classification_folder, category_name)
        if record:
            classification_records.append(record)
            print(f"âœ”ï¸ å·²è®°å½•æ–‡ç« ä¿¡æ¯ã€‚")

    # ä¿å­˜åˆ†ç±»ç»“æœ
    print("\næ­£åœ¨ä¿å­˜åˆ†ç±»ç»“æœ...")
    save_classification_results(classification_records, actual_output_folder, category_name)

    print("\n--- å¾®ä¿¡æ–‡ç« åˆ†ç±»ä»»åŠ¡å®Œæˆ ---")
    print(f"æ€»å…±å¤„ç†äº† {total_files_processed} ä¸ªæ–‡ä»¶ã€‚")


# --- 3. ä¸»é€»è¾‘ ---

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°"""
    print("--- å¼€å§‹æ‰§è¡Œæ–‡æ¡£é‡æ–°åˆ†ç±»ä»»åŠ¡ ---")
    print("æ³¨æ„ï¼šæ­¤åŠŸèƒ½éœ€è¦é…ç½®EXCEL_FILE_PATHå’ŒSOURCE_SUBFOLDERSç­‰å‚æ•°")
    print("å½“å‰è„šæœ¬ä¸»è¦ç”¨äºå¾®ä¿¡æ–‡ç« åˆ†ç±»ï¼Œè¯·ä½¿ç”¨classify_wechat_articleså‡½æ•°")


if __name__ == "__main__":
    main()